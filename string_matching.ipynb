{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import Funktionen as fn\n",
    "import make_train_data as tr\n",
    "import train_and_predict as tp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Methotrexat\n",
       "1    Atezolizumab\n",
       "2      Filgrastim\n",
       "3     Bevacizumab\n",
       "4     Fulvestrant\n",
       "Name: Bezeichnung, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_to_Example_Data = \"https://raw.githubusercontent.com/robert-koch-institut/Bundesweiter_klinischer_Krebsregisterdatensatz-Datenschema_und_Klassifikationen/refs/heads/main/Beispieldaten/csv/substanz.csv\"\n",
    "free_text_data = pd.read_csv(URL_to_Example_Data, sep=\";\")\n",
    "free_text_data[free_text_data[\"TypOfSYST_TypSubstanz\"] == \"Bezeichnung\"]\n",
    "example_data = free_text_data[\"Bezeichnung\"] \n",
    "example_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Therapieart</th>\n",
       "      <th>Substanz</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HO</td>\n",
       "      <td>Abarelix</td>\n",
       "      <td>L02BX01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM</td>\n",
       "      <td>Abatacept</td>\n",
       "      <td>L04AA24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>L01EF03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IM</td>\n",
       "      <td>Abetimus</td>\n",
       "      <td>L04AA22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HO</td>\n",
       "      <td>Abirateron</td>\n",
       "      <td>L02BX03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Therapieart     Substanz     Code\n",
       "0          HO     Abarelix  L02BX01\n",
       "1          IM    Abatacept  L04AA24\n",
       "2          ZS  Abemaciclib  L01EF03\n",
       "3          IM     Abetimus  L04AA22\n",
       "4          HO   Abirateron  L02BX03"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_to_list = \"https://raw.githubusercontent.com/robert-koch-institut/Bundesweiter_klinischer_Krebsregisterdatensatz-Datenschema_und_Klassifikationen/refs/heads/main/Klassifikationen/substanz.csv\"\n",
    "reference_list = pd.read_csv(URL_to_list, sep = \";\")\n",
    "reference_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_substances(input_col, reference_df, split_string = True, split_pattern = r\"[;,]\", fuzzy_threshold=90):\n",
    "\n",
    "    clean_data = fn.preprocessing_func(input_col = input_col, split_string = split_string, \n",
    "                                       split_pattern = split_pattern)\n",
    "    \n",
    "    matches_found = fn.find_matches(processed_df = clean_data,\n",
    "                                    reference_df = reference_df,\n",
    "                                    fuzzy_threshold = fuzzy_threshold)\n",
    "\n",
    "    best_matches = fn.calculate_best_match(processed_df = matches_found,\n",
    "                                           reference_df = reference_df,\n",
    "                                           split_string = split_string)\n",
    "    out = best_matches.rename(columns = {\n",
    "        \"Best_match\": \"Predicted\",\n",
    "        \"LevenshteinPercent\": \"Similarity\"\n",
    "    })\n",
    "\n",
    "    return out.drop(columns = [\"Processed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Original</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Methotrexat</td>\n",
       "      <td>Methotrexat</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Atezolizumab</td>\n",
       "      <td>Atezolizumab</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Filgrastim</td>\n",
       "      <td>Filgrastim</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bevacizumab</td>\n",
       "      <td>Bevacizumab</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fulvestrant</td>\n",
       "      <td>Fulvestrant</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Original     Predicted  Similarity\n",
       "0   1   Methotrexat   Methotrexat       100.0\n",
       "1   2  Atezolizumab  Atezolizumab       100.0\n",
       "2   3    Filgrastim    Filgrastim       100.0\n",
       "3   4   Bevacizumab   Bevacizumab       100.0\n",
       "4   5   Fulvestrant   Fulvestrant       100.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouput_string_matching = get_substances(input_col = example_data,\n",
    "                                        reference_df = reference_list,\n",
    "                                        split_string = True,\n",
    "                                        split_pattern = r\"[;,]\",\n",
    "                                        fuzzy_threshold = 90)\n",
    "ouput_string_matching.to_csv(\"output_string_matchting.csv\", index=False, sep = \";\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "ouput_string_matching.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_uncertain_rows = ouput_string_matching[ouput_string_matching[\"Similarity\"] < 90]\n",
    "df_for_predictions = subset_uncertain_rows.copy()\n",
    "df_for_predictions = df_for_predictions.rename(columns={\"Original\": \"input_text\"})\n",
    "filtered_df = df_for_predictions[(df_for_predictions['input_text'] != \"\") & (df_for_predictions['input_text'].notna())]\n",
    "filtered_df.to_csv(\"df_for_predictions.csv\", sep = \";\", index = False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subs = reference_list[\"Substanz\"].unique().tolist()\n",
    "\n",
    "train_data = pd.DataFrame({\n",
    "    \"input_text\": all_subs,\n",
    "    \"label\": all_subs\n",
    "})\n",
    "\n",
    "word_list = [\"(o.n.a.)\", \"(wÃ¶chentlich)\", \"(i.v.)\", \"(n.n.)\", \"(version)\", \"(lokal)\", \"(zyklus)\"]\n",
    "\n",
    "labeled_train_data = tr.create_labeled_train_data(train_data=train_data, word_list=word_list)\n",
    "labeled_train_data.to_csv(\"labeled_train_data.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a109ce25054a44e6b7359b42a65e2566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [186/186 03:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Val-eval Pearson Cosine</th>\n",
       "      <th>Val-eval Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.785733</td>\n",
       "      <td>0.804151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.789970</td>\n",
       "      <td>0.807392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.793464</td>\n",
       "      <td>0.809802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.804431</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = tp.load_data(\"labeled_train_data.csv\")\n",
    "df['input_text'] = df['input_text'].astype(str)\n",
    "df['label'] = df['label'].astype(str)\n",
    "\n",
    "train_df, val_df = tp.train_test_split(df, test_size=0.2)\n",
    "train_examples = tp.prepare_train_examples(train_df, add_negative_samples=False)\n",
    "val_examples = tp.prepare_train_examples(val_df, add_negative_samples=True)\n",
    " \n",
    "   \n",
    "model = tp.train_model(train_examples, val_examples, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270cf55acf0940ee834e24241410e6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb4eb7b35f24b639ea4298b92049e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "df_for_predictions = tp.load_data(\"df_for_predictions.csv\")\n",
    "reference_list_input = reference_list[\"Substanz\"].str.strip().unique().tolist()\n",
    "tp.predict_substances_batch(df_for_predictions, model, reference_list_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID      Original     Predicted  Similarity           Method Flag\n",
      "0      1   Methotrexat   Methotrexat       100.0  String_Matching   no\n",
      "1      2  Atezolizumab  Atezolizumab       100.0  String_Matching   no\n",
      "2      3    Filgrastim    Filgrastim       100.0  String_Matching   no\n",
      "3      4   Bevacizumab   Bevacizumab       100.0  String_Matching   no\n",
      "4      5   Fulvestrant   Fulvestrant       100.0  String_Matching   no\n",
      "..   ...           ...           ...         ...              ...  ...\n",
      "195  196    Ribociclib    Ribociclib       100.0  String_Matching   no\n",
      "196  197  Fluorouracil  Fluorouracil       100.0  String_Matching   no\n",
      "197  198           NaN           NaN         0.0  String_Matching  yes\n",
      "198  199           NaN           NaN         0.0  String_Matching  yes\n",
      "199  200           NaN           NaN         0.0  String_Matching  yes\n",
      "\n",
      "[216 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "model_matches = pd.read_csv(\"predictions.csv\", sep = \";\")\n",
    "model_matches[\"Method\"] = \"ML_Model\"\n",
    "string_matches = pd.read_csv(\"output_string_matchting.csv\", sep = \";\")\n",
    "string_matches[\"Method\"] = \"String_Matching\"\n",
    "\n",
    "extracted_substances = pd.concat([string_matches, model_matches], ignore_index=True).sort_values(by=\"ID\", ascending=True)\n",
    "extracted_substances[\"Flag\"] = np.where(extracted_substances[\"Similarity\"] <= 90, \"yes\", \"no\")\n",
    "\n",
    "print(extracted_substances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
